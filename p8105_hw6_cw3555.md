p8105_hw6_cw3555
================
Eunice Wang
`2023-12-02`

Load key packages.

``` r
library(tidyverse)
library(modelr)
library(p8105.datasets)

set.seed(1)
```

### Problem 1

#### Load and clean the raw data.

``` r
homicide_df=
  read_csv("data/homicide-data.csv") |> 
  janitor::clean_names() |> 
  mutate(
    city_state=str_c(city,state,sep =", "),
    resolved = as.numeric(disposition == "Closed by arrest"), 
    victim_age=as.numeric(victim_age)
    )|> 
      filter(!city_state %in% c("Dallas, TX","Phoenix, AZ", "Kansas City, MO", "Tulsa, AL" )) |> 
      filter(victim_race %in% c("Black", "White")) |> 
  select(city_state,resolved, victim_age, victim_sex, victim_race)
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Fit a logistic regression for Baltimore, MD and save the results for estimates

``` r
fit_baltimore=
  homicide_df |> 
  filter(city_state=="Baltimore, MD") |> 
  glm(
    resolved ~ victim_age + victim_sex + victim_race, 
    data = _, 
    family = binomial())

baltimore_results=
fit_baltimore |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate),
    OR_CI_lower = exp(estimate-1.96*std.error),
    OR_CI_upper = exp(estimate+1.96*std.error)
    ) |> 
  filter(term=="victim_sexMale") |> 
  select(OR,OR_CI_lower,OR_CI_upper) 
```

The estimated proportion of unsolve homicides in Baltimore, MD is
0.4255117and the CI is \[0.324559, 0.5578655\]

#### Fit a logistic regression for each of the cities and save the results for estimates

``` r
city_glm_model=
  homicide_df |> 
  nest(df = -city_state) |> 
  mutate(
    models = map(df, \(df) glm(resolved ~ victim_age + victim_sex +victim_race, family = binomial(), data = df)),
    results = map(models, broom::tidy)
  ) |>
  select(city_state, results) |> 
  unnest(results) |> 
  mutate(
    OR = exp(estimate),
    OR_CI_lower = exp(estimate-1.96*std.error),
    OR_CI_upper = exp(estimate+1.96*std.error)
    ) |> 
    filter(term=="victim_sexMale") |> 
    select(city_state,OR,OR_CI_lower,OR_CI_upper) 

city_glm_model |> 
  head() |> 
  knitr::kable(digits = 2) 
```

| city_state      |   OR | OR_CI_lower | OR_CI_upper |
|:----------------|-----:|------------:|------------:|
| Albuquerque, NM | 1.77 |        0.83 |        3.76 |
| Atlanta, GA     | 1.00 |        0.68 |        1.46 |
| Baltimore, MD   | 0.43 |        0.32 |        0.56 |
| Baton Rouge, LA | 0.38 |        0.21 |        0.70 |
| Birmingham, AL  | 0.87 |        0.57 |        1.32 |
| Boston, MA      | 0.67 |        0.36 |        1.28 |

#### Create a plot that shows the estimates for each city and comment

``` r
city_glm_model |>  
  ggplot(aes(x=fct_reorder(city_state, OR), y=OR, ymin=OR_CI_lower, ymax=OR_CI_upper))+
  geom_point()+
  geom_errorbar()+
  theme(axis.text.x=element_text(angle=90, vjust=0.5,hjust=1))+
  labs(
    x="City_State",
    y="Adjuested Estimated Odds Ratio" ,
    title="The estimated ORs and CIs for each city"
  )
```

<img src="p8105_hw6_cw3555_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

The plots shows the estimated ORs and CIs for each city. The estimated
odds ratio is ordered from the smallest estimated OR to the largest one.
In most cities, the estimated odds ratio is less than 1. CIs in most
cities are narrow and do not contain 1, which implies a significant
difference in resolved rates between both sexes after adjustment.

### Problem 2

#### Load and clean the raw data.

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

    ## using cached file: /Users/mac/Library/Caches/org.R-project.R/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2023-10-04 16:33:34.519205 (8.527)

    ## file min/max dates: 1869-01-01 / 2023-10-31

#### Fit a linear regression

``` r
weather_lm=
  lm(tmax ~ tmin+prcp, data=weather_df)
broom::tidy(weather_lm)
```

    ## # A tibble: 3 × 5
    ##   term        estimate std.error statistic   p.value
    ##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>
    ## 1 (Intercept)  8.04      0.230      35.0   4.39e-118
    ## 2 tmin         1.01      0.0162     62.7   1.43e-196
    ## 3 prcp        -0.00154   0.00210    -0.733 4.64e-  1

``` r
broom::glance(weather_lm)
```

    ## # A tibble: 1 × 12
    ##   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC
    ##       <dbl>         <dbl> <dbl>     <dbl>     <dbl> <dbl>  <dbl> <dbl> <dbl>
    ## 1     0.916         0.915  2.96     1972. 2.19e-195     2  -912. 1832. 1848.
    ## # ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>

#### Bootstrap for r̂ 2

``` r
boot_results_rsq = 
  weather_df |> 
   modelr::bootstrap(n = 5000) |> 
   mutate(
    models = map(strap, \(df) lm(tmax ~ tmin+prcp, data=df)),
    results = map(models, broom::glance),
  ) |> 
  select(results) |> 
  unnest(results) 
```

Make a plot of r̂ 2

``` r
boot_results_rsq|> 
  select(r.squared) |> 
  ggplot(aes(x=r.squared))+
  geom_density()+
  labs(
    x="Bootstrap R-squared",
    y="Frequency",
    title="Distribution of Bootstrap Estimated R-squared"
  )
```

<img src="p8105_hw6_cw3555_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

This plot for `r-squared` measure the goodness of fit regarding a model.
From the plot, we can see that most of the estimates of `r-squared`
range from 0.90 to 0.94, with a peak around 0.92. The majority of the
bootstrap samples has a value of 0.92 for its `r_squared`.This indicates
a generally good fit of the model. The distribution is slightly skewed
to the left.

Provide the 95% confidence interval for r̂ 2

``` r
CI_r_squared=
  boot_results_rsq|> 
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)
  ) 
```

The CI for `r_squared` is \[0.8885495, 0.9406812\]

#### Bootstrap for log(β̂ 1∗β̂ 2

``` r
boot_results_log_beta = 
  weather_df |> 
   modelr::bootstrap(n = 5000) |> 
   mutate(
    models = map(strap, \(df) lm(tmax ~ tmin+prcp, data=df)),
    results = map(models, broom::tidy),
  ) |> 
  select(id=.id, results) |> 
  unnest(results) |> 
  select(id, term, estimate) |> 
  pivot_wider(
    names_from=term,
    values_from=estimate) |> 
  rename(beta_1=tmin, beta_2=prcp)
```

Make a plot for log(β̂ 1∗β̂ 2)

``` r
filtered_boot_results=
  boot_results_log_beta |> 
  filter(beta_1*beta_2>0) |> 
  mutate(log_beta_product=log(beta_1*beta_2))

filtered_boot_results|> 
  ggplot(aes(x=pull(filtered_boot_results, log_beta_product)))+
  geom_density()+
  labs(
    x="Bootstrap Log(Beat1*Beta2)",
    y="Frequency",
    title="Distribution of Bootstrap Estimated Log(Beat1*Beta2)"
  )
```

<img src="p8105_hw6_cw3555_files/figure-gfm/unnamed-chunk-13-1.png" width="90%" />

This plot for `log(beat1*beta2)` has a left-skewed distribution wuth a
long tail extending towards lower values. From the plot, we can see that
most of the estimates of `log(beat1*beta2)` lies in -7 to -5, with a
peak around -5.5.The majority of the bootstrap samples has a value of
-5.5 for its `log(beat1*beta2)`, indicating a moderate influence of the
two factors.

Provide the 95% confidence interval for log(β̂ 1∗β̂ 2)

``` r
CI_log_beta_product=
  filtered_boot_results|> 
  summarize(
    ci_lower = quantile(log_beta_product, 0.025),
    ci_upper = quantile(log_beta_product, 0.975)
  )
```

The CI for `log_beta_product` is \[-8.8847595, -4.6039854\]
